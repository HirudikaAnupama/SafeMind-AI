{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.476087Z",
     "start_time": "2024-12-19T20:26:16.396051Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.554855Z",
     "start_time": "2024-12-19T20:26:17.478326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read json file\n",
    "data = pd.read_json(\"data/combined_dataset.json\", lines=True)"
   ],
   "id": "50eee525d902619",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.573516Z",
     "start_time": "2024-12-19T20:26:17.555856Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "8bcef4d8a6f05f5f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "3507  My grandson's step-mother sends him to school ...   \n",
       "3508  My boyfriend is in recovery from drug addictio...   \n",
       "3509  The birth mother attempted suicide several tim...   \n",
       "3510  I think adult life is making him depressed and...   \n",
       "3511  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \n",
       "0     If everyone thinks you're worthless, then mayb...  \n",
       "1     Hello, and thank you for your question and see...  \n",
       "2     First thing I'd suggest is getting the sleep y...  \n",
       "3     Therapy is essential for those that are feelin...  \n",
       "4     I first want to let you know that you are not ...  \n",
       "...                                                 ...  \n",
       "3507  Absolutely not! It is never in a child's best ...  \n",
       "3508  I'm sorry you have tension between you and you...  \n",
       "3509  The true answer is, \"no one can really say wit...  \n",
       "3510  How do you help yourself to believe you requir...  \n",
       "3511                           hmm this is a tough one!  \n",
       "\n",
       "[3512 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>My grandson's step-mother sends him to school ...</td>\n",
       "      <td>Absolutely not! It is never in a child's best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>hmm this is a tough one!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.587243Z",
     "start_time": "2024-12-19T20:26:17.575531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display dataset info\n",
    "data.info()"
   ],
   "id": "e7b4a62c60808fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3512 entries, 0 to 3511\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Context   3512 non-null   object\n",
      " 1   Response  3512 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 55.0+ KB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data cleaning\n",
    "#### Remove duplicates"
   ],
   "id": "dce9feb760412e4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.618619Z",
     "start_time": "2024-12-19T20:26:17.588244Z"
    }
   },
   "cell_type": "code",
   "source": "data.duplicated().sum()",
   "id": "b559bd4ee3b772c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.642939Z",
     "start_time": "2024-12-19T20:26:17.619630Z"
    }
   },
   "cell_type": "code",
   "source": "data.drop_duplicates(inplace=True)",
   "id": "d79f5a756daaffae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.666237Z",
     "start_time": "2024-12-19T20:26:17.643941Z"
    }
   },
   "cell_type": "code",
   "source": "data.duplicated().sum()",
   "id": "49bed409e83e4ab7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Remove missing values",
   "id": "d935ec2b7c5faf32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.676879Z",
     "start_time": "2024-12-19T20:26:17.667590Z"
    }
   },
   "cell_type": "code",
   "source": "data.isna().sum()",
   "id": "29f033a37455ae71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context     0\n",
       "Response    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean the Context Text",
   "id": "c1d03ebcf1e4157a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.682512Z",
     "start_time": "2024-12-19T20:26:17.677888Z"
    }
   },
   "cell_type": "code",
   "source": "import re",
   "id": "fd511dbe2b8fc3c9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.764699Z",
     "start_time": "2024-12-19T20:26:17.687772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove Extra Spaces, Tabs, and Newlines\n",
    "data['Context'] = data['Context'].str.replace(r\"\\s+\", \" \", regex=True).str.strip()"
   ],
   "id": "87d7ba55bad95cab",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.817458Z",
     "start_time": "2024-12-19T20:26:17.766702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardize Capitalization\n",
    "data['Context'] = data['Context'].str.lower()\n",
    "data['Context'] = data['Context'].str.replace(r\"(^\\w|\\.\\s*\\w)\", lambda m: m.group().upper(), regex=True)\n"
   ],
   "id": "cfd56a28660b7ca1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.890068Z",
     "start_time": "2024-12-19T20:26:17.818459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove Sensitive Data\n",
    "data['Context'] = data['Context'].str.replace(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\", \"[EMAIL]\", regex=True)\n",
    "data['Context'] = data['Context'].str.replace(r\"\\b\\d{10}\\b\", \"[PHONE NUMBER]\", regex=True)\n"
   ],
   "id": "3a2c95e9631f0f4f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:17.947062Z",
     "start_time": "2024-12-19T20:26:17.892332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize Punctuation\n",
    "data['Context'] = data['Context'].str.replace(r\"[?!]+\", lambda m: m.group()[0], regex=True)\n",
    "data['Context'] = data['Context'].str.replace(r\"([.,!?])(\\w)\", r\"\\1 \\2\", regex=True)\n",
    "data['Context'] = data['Context'].str.replace(r\"\\s([.,!?])\", r\"\\1\", regex=True)\n"
   ],
   "id": "dced7b5337c5a683",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clean the Response Text",
   "id": "28f18ab1ca5c0b31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.182961Z",
     "start_time": "2024-12-19T20:26:17.948088Z"
    }
   },
   "cell_type": "code",
   "source": "data['Response'] = data['Response'].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
   "id": "a1b9837ecb67e04a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.305694Z",
     "start_time": "2024-12-19T20:26:18.184991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['Response'] = data['Response'].str.lower()\n",
    "data['Response'] = data['Response'].str.replace(r\"(^\\w|\\.\\s*\\w)\", lambda m: m.group().upper(), regex=True)\n"
   ],
   "id": "e30f7c9006940a28",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.535766Z",
     "start_time": "2024-12-19T20:26:18.307699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['Response'] = data['Response'].str.replace(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\", \"[EMAIL]\", regex=True)\n",
    "data['Response'] = data['Response'].str.replace(r\"\\b\\d{10}\\b\", \"[PHONE NUMBER]\", regex=True)\n"
   ],
   "id": "f22109431ecdc937",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.703965Z",
     "start_time": "2024-12-19T20:26:18.537772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['Response'] = data['Response'].str.replace(r\"[?!]+\", lambda m: m.group()[0], regex=True)\n",
    "data['Response'] = data['Response'].str.replace(r\"([.,!?])(\\w)\", r\"\\1 \\2\", regex=True)\n",
    "data['Response'] = data['Response'].str.replace(r\"\\s([.,!?])\", r\"\\1\", regex=True)\n"
   ],
   "id": "1d1d7b80ca3d44a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.768735Z",
     "start_time": "2024-12-19T20:26:18.704967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save to a new JSON file\n",
    "data.to_json(\"data/cleaned_dataset.json\", orient=\"records\", lines=True)\n",
    "\n",
    "print(\"Dataset cleaned and saved as 'data/cleaned_dataset.json'.\")\n"
   ],
   "id": "775c868fce7b50b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleaned and saved as 'data/cleaned_dataset.json'.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.823259Z",
     "start_time": "2024-12-19T20:26:18.769739Z"
    }
   },
   "cell_type": "code",
   "source": "clean_data = pd.read_json(\"data/cleaned_dataset.json\", lines=True)",
   "id": "55ad624f8ebbf07e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:18.835457Z",
     "start_time": "2024-12-19T20:26:18.824268Z"
    }
   },
   "cell_type": "code",
   "source": "clean_data",
   "id": "b7f96c017a1092a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "2747  After first meeting the client, what is the pr...   \n",
       "2748  My boyfriend is in recovery from drug addictio...   \n",
       "2749  The birth mother attempted suicide several tim...   \n",
       "2750  I think adult life is making him depressed and...   \n",
       "2751  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \n",
       "0     If everyone thinks you're worthless, then mayb...  \n",
       "1     Hello, and thank you for your question and see...  \n",
       "2     First thing i'd suggest is getting the sleep y...  \n",
       "3     Therapy is essential for those that are feelin...  \n",
       "4     I first want to let you know that you are not ...  \n",
       "...                                                 ...  \n",
       "2747  Hi. This is an excellent question! i think tha...  \n",
       "2748  I'm sorry you have tension between you and you...  \n",
       "2749  The true answer is, \"no one can really say wit...  \n",
       "2750  How do you help yourself to believe you requir...  \n",
       "2751                           Hmm this is a tough one!  \n",
       "\n",
       "[2752 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing i'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>After first meeting the client, what is the pr...</td>\n",
       "      <td>Hi. This is an excellent question! i think tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>Hmm this is a tough one!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2752 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization",
   "id": "e40e0759a1a93d2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:29.121463Z",
     "start_time": "2024-12-19T20:26:18.836519Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer",
   "id": "58ebeddf9771fd84",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:30.217259Z",
     "start_time": "2024-12-19T20:26:29.122465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the tokenizer\n",
    "model_name = \"gpt2\"  # Replace with your desired model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Assign the eos_token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ],
   "id": "3a7f512f3754b23a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:32.676085Z",
     "start_time": "2024-12-19T20:26:30.218261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize the input and output columns\n",
    "input_ids = tokenizer(list(clean_data[\"Context\"]), padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
    "output_ids = tokenizer(list(clean_data[\"Response\"]), padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids"
   ],
   "id": "fa2bb35f8aa722e0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:59.873441Z",
     "start_time": "2024-12-19T20:26:59.854528Z"
    }
   },
   "cell_type": "code",
   "source": "input_ids",
   "id": "e1ae8186012b76af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,  1101,  1016,  ..., 50256, 50256, 50256],\n",
       "        [   40,  1101,  1016,  ..., 50256, 50256, 50256],\n",
       "        [   40,  1101,  1016,  ..., 50256, 50256, 50256],\n",
       "        ...,\n",
       "        [  464,  4082,  2802,  ..., 50256, 50256, 50256],\n",
       "        [   40,   892,  4044,  ..., 50256, 50256, 50256],\n",
       "        [   40,   655,  1718,  ..., 50256, 50256, 50256]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:32.685962Z",
     "start_time": "2024-12-19T20:26:32.678090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine into a single dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, input_ids, output_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.output_ids = output_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"labels\": self.output_ids[idx],\n",
    "        }\n",
    "\n",
    "# Create the dataset object\n",
    "dataset = TextDataset(input_ids, output_ids)"
   ],
   "id": "26c76ead664c2d2c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Fine-Tune the Model",
   "id": "2c1e3be0c3c87540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:52.785988Z",
     "start_time": "2024-12-19T20:26:32.687651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ],
   "id": "6d5f0910f9ec6626",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Define training arguments\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m training_args \u001B[38;5;241m=\u001B[39m \u001B[43mTrainingArguments\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./results\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_train_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mper_device_train_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_total_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogging_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./logs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Initialize the trainer\u001B[39;00m\n\u001B[0;32m     17\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     18\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     19\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[0;32m     20\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mdataset,\n\u001B[0;32m     21\u001B[0m )\n",
      "File \u001B[1;32m<string>:134\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:1780\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1778\u001B[0m \u001B[38;5;66;03m# Initialize device before we proceed\u001B[39;00m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_torch_available():\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;66;03m# Disable average tokens when using single device\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maverage_tokens_across_devices:\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:2306\u001B[0m, in \u001B[0;36mTrainingArguments.device\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2302\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2303\u001B[0m \u001B[38;5;124;03mThe device used by this process.\u001B[39;00m\n\u001B[0;32m   2304\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2305\u001B[0m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m-> 2306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_devices\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:60\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[1;34m(self, obj, objtype)\u001B[0m\n\u001B[0;32m     58\u001B[0m cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 60\u001B[0m     cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\training_args.py:2179\u001B[0m, in \u001B[0;36mTrainingArguments._setup_devices\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[0;32m   2178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[1;32m-> 2179\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m   2180\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2181\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccelerate>=\u001B[39m\u001B[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2182\u001B[0m         )\n\u001B[0;32m   2183\u001B[0m \u001B[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001B[39;00m\n\u001B[0;32m   2184\u001B[0m accelerator_state_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menabled\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_configured_state\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m}\n",
      "\u001B[1;31mImportError\u001B[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Save the Fine-Tuned Model\n",
   "id": "dbe14650d9a98b48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T20:26:52.790027Z",
     "start_time": "2024-12-19T20:26:52.789024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "print(\"Model and tokenizer saved!\")\n"
   ],
   "id": "4af4e826d7d3386e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  Deploy as a Chatbot",
   "id": "98500b457b4080f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_saved_model(model_path):\n",
    "    \"\"\"\n",
    "    Load the saved model and tokenizer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        # Load the model\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "        \n",
    "        # Move model to GPU if available\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = model.to(device)\n",
    "        \n",
    "        return model, tokenizer\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading saved model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def generate_response(model, tokenizer, prompt, max_length=200):\n",
    "    \"\"\"\n",
    "    Generate a response using the saved model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare the input\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # Generate response\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids, \n",
    "            max_length=max_length, \n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Decode the response\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Interactive chat interface to input questions and get responses.\n",
    "    \"\"\"\n",
    "    # Path to the saved model\n",
    "    model_path = \"./fine_tuned_model\"\n",
    "    \n",
    "    # Load the saved model and tokenizer\n",
    "    model, tokenizer = load_saved_model(model_path)\n",
    "    \n",
    "    if not model or not tokenizer:\n",
    "        print(\"Failed to load the saved model.\")\n",
    "        return\n",
    "    \n",
    "    print(\"🤖 Interactive Model Response\")\n",
    "    print(\"Type 'exit' to quit the program\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_input = input(\"\\nEnter your question: \").strip()\n",
    "            \n",
    "            # Check for exit condition\n",
    "            if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "                print(\"Goodbye! 👋\")\n",
    "                break\n",
    "            \n",
    "            # Generate and print response\n",
    "            if user_input:\n",
    "                response = generate_response(model, tokenizer, user_input)\n",
    "                print(\"\\nModel's Response:\", response)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nChat interrupted. Goodbye! 👋\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat()"
   ],
   "id": "19e29ea844d3a77d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "83527064172822ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fc6e73382220daa7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c7c1692475755cc4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
